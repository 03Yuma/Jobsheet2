{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO75ZyGk5ODcfdnP8uapFUO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/03Yuma/Machine_Learning/blob/main/Jobsheet11_P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsk3QvAimr4G",
        "outputId": "fa9eae8a-ecbc-46d3-89f3-b9ab4f3f1710"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bo2l5BrfkSSt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/PCVK/machineLearning/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhM-W6Q9kZLP",
        "outputId": "7df2d769-25a0-4e5f-db3a-ae180b2eccf9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8004 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/PCVK/machineLearning/dataset/training_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "id": "yojgdTRrkbac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ab6ce3-a17e-4d12-b438-48c860b9878a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8004 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pembukaan Model CNN**"
      ],
      "metadata": {
        "id": "-JFjKNZ__OF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "zpAdGf3l-cFg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "yaN8pe8h-ruU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "YPb7y-jC-tIJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "YM6K778D-vhW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "oUTMax1I-xER"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "w-EauvHT_CZU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "GwO8XVRU_FjB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "UiwEPs6P_JSm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fit CNN**"
      ],
      "metadata": {
        "id": "6sbLMw0P_T4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4UkT8df_KuK",
        "outputId": "9fb01d6b-9ce9-4d66-8c43-d2f94b1e9a4a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1513s\u001b[0m 6s/step - accuracy: 0.5323 - loss: 0.6887 - val_accuracy: 0.5454 - val_loss: 0.7822\n",
            "Epoch 2/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 681ms/step - accuracy: 0.6553 - loss: 0.6145 - val_accuracy: 0.7169 - val_loss: 0.5495\n",
            "Epoch 3/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 576ms/step - accuracy: 0.7055 - loss: 0.5682 - val_accuracy: 0.7430 - val_loss: 0.5116\n",
            "Epoch 4/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 575ms/step - accuracy: 0.7404 - loss: 0.5193 - val_accuracy: 0.7725 - val_loss: 0.4747\n",
            "Epoch 5/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 688ms/step - accuracy: 0.7552 - loss: 0.4954 - val_accuracy: 0.7635 - val_loss: 0.4801\n",
            "Epoch 6/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 580ms/step - accuracy: 0.7676 - loss: 0.4846 - val_accuracy: 0.8095 - val_loss: 0.4134\n",
            "Epoch 7/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 569ms/step - accuracy: 0.7801 - loss: 0.4583 - val_accuracy: 0.7817 - val_loss: 0.4556\n",
            "Epoch 8/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 578ms/step - accuracy: 0.7905 - loss: 0.4465 - val_accuracy: 0.8136 - val_loss: 0.4007\n",
            "Epoch 9/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 587ms/step - accuracy: 0.7914 - loss: 0.4395 - val_accuracy: 0.8170 - val_loss: 0.3967\n",
            "Epoch 10/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 693ms/step - accuracy: 0.8123 - loss: 0.4136 - val_accuracy: 0.8286 - val_loss: 0.3726\n",
            "Epoch 11/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 696ms/step - accuracy: 0.8216 - loss: 0.3909 - val_accuracy: 0.8261 - val_loss: 0.3790\n",
            "Epoch 12/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 578ms/step - accuracy: 0.8201 - loss: 0.3882 - val_accuracy: 0.8480 - val_loss: 0.3438\n",
            "Epoch 13/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 581ms/step - accuracy: 0.8244 - loss: 0.3749 - val_accuracy: 0.8336 - val_loss: 0.3648\n",
            "Epoch 14/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 579ms/step - accuracy: 0.8338 - loss: 0.3720 - val_accuracy: 0.8460 - val_loss: 0.3375\n",
            "Epoch 15/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 573ms/step - accuracy: 0.8347 - loss: 0.3653 - val_accuracy: 0.8561 - val_loss: 0.3228\n",
            "Epoch 16/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 585ms/step - accuracy: 0.8421 - loss: 0.3508 - val_accuracy: 0.8717 - val_loss: 0.2948\n",
            "Epoch 17/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 577ms/step - accuracy: 0.8514 - loss: 0.3281 - val_accuracy: 0.8772 - val_loss: 0.2838\n",
            "Epoch 18/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 697ms/step - accuracy: 0.8523 - loss: 0.3305 - val_accuracy: 0.8774 - val_loss: 0.2866\n",
            "Epoch 19/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 689ms/step - accuracy: 0.8495 - loss: 0.3226 - val_accuracy: 0.8856 - val_loss: 0.2620\n",
            "Epoch 20/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 583ms/step - accuracy: 0.8610 - loss: 0.3079 - val_accuracy: 0.8683 - val_loss: 0.2957\n",
            "Epoch 21/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 576ms/step - accuracy: 0.8624 - loss: 0.3031 - val_accuracy: 0.8871 - val_loss: 0.2606\n",
            "Epoch 22/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 697ms/step - accuracy: 0.8612 - loss: 0.3021 - val_accuracy: 0.8887 - val_loss: 0.2674\n",
            "Epoch 23/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 692ms/step - accuracy: 0.8759 - loss: 0.2910 - val_accuracy: 0.8939 - val_loss: 0.2448\n",
            "Epoch 24/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 698ms/step - accuracy: 0.8861 - loss: 0.2700 - val_accuracy: 0.9053 - val_loss: 0.2266\n",
            "Epoch 25/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 692ms/step - accuracy: 0.8850 - loss: 0.2681 - val_accuracy: 0.8729 - val_loss: 0.2894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f8560992050>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/PCVK/machineLearning/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R53wFkh_fgi",
        "outputId": "c52aa621-379f-4de1-b1d3-84d093da8053"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n"
          ]
        }
      ]
    }
  ]
}